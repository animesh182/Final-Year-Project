{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/animesh182/Final-Year-Project/blob/main/ganfull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skQjIiKsQGSK"
      },
      "source": [
        "IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "RlqdYg7bQGSQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow import keras\n",
        "import pathlib\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import PReLU\n",
        "from IPython import display\n",
        "import random\n",
        "from matplotlib import pyplot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7r6S9c1QGSS"
      },
      "source": [
        "DEFINING DISCRIMINATOR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "AIfZPZTqQGSS"
      },
      "outputs": [],
      "source": [
        "def get_discriminator_model(channels=1):\n",
        "    \n",
        "    input = (96,96,channels)\n",
        "    model = Sequential()\n",
        "    filter=[64,64,128,128,256,256,512,512]\n",
        "    for id, size in enumerate(filter):\n",
        "\n",
        "      model.add(layers.Conv2D(size,kernel_size = 3, strides=id % 2 + 1, padding=\"same\"))\n",
        "      if(id!=0):\n",
        "        model.add(BatchNormalization())\n",
        "      model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                                                      DEFINING GENERATOR MODEL"
      ],
      "metadata": {
        "id": "JwawoO5oIHM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_generator_model(channels=1):           # Main Method that returns gen model\n",
        "  input = (24,24,channels)\n",
        "  model= Sequential()\n",
        "  model.add(layers.Conv2D(64,kernel_size=9,strides=1,padding=\"same\"))\n",
        "  model.add(PReLU())\n",
        "  NewModel= get_generator_residual(model)\n",
        "  FinalModel = get_generator_shuffler(NewModel)\n",
        "  return FinalModel\n",
        "\n",
        "  \n",
        "def get_generator_residual(model, kernel_size=3, filters=64, stride=1):\n",
        "  iterator = np.arange(1,6)\n",
        "  for x in iterator:\n",
        "    model.add(layers.Conv2D(filters,kernel_size, stride, padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    if x!=6:\n",
        "      model.add(PReLU())\n",
        "      model.add(layers.Conv2D(filters,kernel_size, stride, padding=\"same\"))\n",
        "      model.add(PReLU())\n",
        "  \n",
        "  return model\n",
        "\n",
        "def get_generator_shuffler(model, kernel_size=3,filters=256,stride=1,upscale_factor=2):\n",
        "  iterator = np.arange(1,2)\n",
        "  image_size=24\n",
        "  for  x in iterator:\n",
        "    image_size*=upscale_factor\n",
        "    model.add(layers.Conv2D(filters,kernel_size,stride,padding=\"same\"))\n",
        "    model.add(Reshape((image_size,image_size )))\n",
        "    model.add(PReLU())\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eB6ABDLqPVr0"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING ACTUAL GAN MODEL"
      ],
      "metadata": {
        "id": "YjP-q8S3zjog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gan_model(gen_model, dis_model):\n",
        "  dis_model.trainable = False\n",
        "  model = Sequential()\n",
        "  model.add(gen_model)\n",
        "  model.add(dis_model)\n",
        "  optimz = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=optimz,metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "EArP7tfPznEr"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nATCIbpIQGSU"
      },
      "source": [
        "                        DATA SOURCE FOR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZiGIg-qSb8X",
        "outputId": "9fc59754-f0a3-4050-af48-5218d532aaa1"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "fMOEG7zkQGSV"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/gdrive/MyDrive/dataset\"\n",
        "root_dir = pathlib.Path(root_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HizrDWDtQGSW"
      },
      "source": [
        "                    SPLITTING DATA INTO VALIDATION AND TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSMHdR_hQGSX",
        "outputId": "f67986a0-4752-4996-c268-f0a7333eec13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5160 files belonging to 1 classes.\n",
            "Using 4128 files for training.\n",
            "Found 5160 files belonging to 1 classes.\n",
            "Using 1032 files for validation.\n"
          ]
        }
      ],
      "source": [
        "crop_size = (24, 24)\n",
        "batch_size = 64\n",
        "upscale_factor = 4\n",
        "input_size = 24 \n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    root_dir,\n",
        "    batch_size=batch_size,\n",
        "    image_size=crop_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    label_mode=None,\n",
        ")\n",
        "\n",
        "valid_ds = image_dataset_from_directory(\n",
        "    root_dir,\n",
        "    batch_size=batch_size,\n",
        "    image_size=crop_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    label_mode=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT1SrOR9QGSY"
      },
      "source": [
        "                              PREPPING DATASET FOR MODEL INPUT AND COMPARISON\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "k6UHFeOQQGSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71622d4a-4df4-4cc2-e436-24fbc7592b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 24, 24, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 24, 24, 1), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "def normalize(images):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images\n",
        "\n",
        "# The map function applies the normalize function to each element in the train\n",
        "# and test datasets\n",
        "train_ds =  train_ds.map(normalize)\n",
        "\n",
        "valid_ds  =  valid_ds.map(normalize)\n",
        "\n",
        "# The first time you use the dataset, the images will be loaded from disk\n",
        "# Caching will keep them in memory, making training faster\n",
        "\n",
        "def process_input(input, input_size, upscale_factor):\n",
        "    input = tf.image.rgb_to_yuv(input)\n",
        "    last_dimension_axis = len(input.shape) - 1\n",
        "    y, u, v = tf.split(input, 3, axis=last_dimension_axis)\n",
        "    return tf.image.resize(y, [input_size, input_size], method=\"area\")\n",
        "\n",
        "\n",
        "def process_target(input):\n",
        "    input = tf.image.rgb_to_yuv(input)\n",
        "    last_dimension_axis = len(input.shape) - 1\n",
        "    y, u, v = tf.split(input, 3, axis=last_dimension_axis)\n",
        "    return y\n",
        "\n",
        "def get_lowres_image(img, upscale_factor):\n",
        "    return img.resize((img.size[0] // upscale_factor, img.size[1] // upscale_factor), PIL.Image.BICUBIC,)\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    lambda x: (process_input(x, input_size=24, upscale_factor=3), process_target(x))\n",
        ")\n",
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x: (process_input(x, input_size=24, upscale_factor=3), process_target(x))\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(buffer_size=32)\n",
        "print(train_ds)#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMzsbiOGQGSZ"
      },
      "source": [
        "                                                REAL(SUPER RESOLUTIONED SAMPLES FROM GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "wnxuiLR8QGSa"
      },
      "outputs": [],
      "source": [
        "def real_sample_generator(dataset, samples):\n",
        "  rd = 0\n",
        "  selected_real= 0 \n",
        "  numbering = 0\n",
        "  for x in dataset:\n",
        "    y = np.asarray(x[1], dtype='object')\n",
        "    rd = np.random.randint(0,int(y.shape[0]),int(samples))\n",
        "    selected_real = y[rd].astype('float32')\n",
        "    numbering = np.ones((samples,1))\n",
        "    print(\"...\")\n",
        "  return selected_real, numbering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiEM6eAkQGSa"
      },
      "source": [
        "        FAKE SAMPLES FOR DISCRIMINATOR AKA REAL SAMPLES FROM GENERATOR\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "D-f0wwMkQGSb"
      },
      "outputs": [],
      "source": [
        "def fake_sample_generator(gen_model, images, samples):\n",
        "  dataset = get_lowres_image(images,upscale_factor)\n",
        "  for x in dataset:\n",
        "     fake_samples= gen_model.predict(x)\n",
        "     numbering = np.ones((samples,1))\n",
        "     print(\"...\")\n",
        "  return fake_samples, numbering\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING GENERATED SAMPLES"
      ],
      "metadata": {
        "id": "V6GkHi9wOa-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tpyplot.savefig(filename)\n",
        "\tpyplot.close()"
      ],
      "metadata": {
        "id": "eBwCQfyZOadr"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATING THE DISCRIMINATOR AND SAVING MODEL\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-r82MgSNO-EQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "BPeUzJ2YQGSc"
      },
      "outputs": [],
      "source": [
        "def model_evaluation(gen_model,dis_model, dataset, epoch, iteration = 100, batch =256):\n",
        "    half_batch = int(batch_size/2)\n",
        "    for i in range(iteration):\n",
        "        x_real,y_real = real_sample_generator(dataset, half_batch)\n",
        "        print(\"finished\")\n",
        "        _,real_accuracy = dis_model.evaluate(x_real,y_real,verbose=0)\n",
        "        print(\"finished accuracy calculation\")\n",
        "        x_fake,y_fake = fake_sample_generator(gen_model,dataset,half_batch)\n",
        "        print(\"finished2\")\n",
        "        _,fake_accuracy = dis_model.train_on_batch(x_fake,y_fake)\n",
        "        print('>%d real= %.0f%% fake = %.0f%%'%(i+1,real_accuracy*100,fake_accuracy*100))\n",
        "        save_plot(x_fake, epoch)\n",
        "\n",
        "\n",
        "        filename = 'generator_model_%03d.h5' % (epoch + 1)\n",
        "        gen_model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "ssK8PP0VUWHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(gen_model,dis_model, gan_model, dataset,epochs=100,batch=256):\n",
        "  batch_per_epoch=int(dataset[2].shape[0]/batch)\n",
        "  half_batch=int(batch/2)\n",
        "  for x in range(batch_per_epoch):\n",
        "    X_real, y_real = real_sample_generator(dataset, half_batch)\n",
        "    X_fake, y_fake = fake_sample_generator(dataset , half_batch)\n",
        "    X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
        "    d_loss, _ = dis_model.train_on_batch(X, y)\n",
        "    X_gan = get_lowres_image(train_ds, batch)\n",
        "    y_gan = np.ones((batch, 1))\n",
        "    g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "    print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, batch_per_epoch, d_loss, g_loss))\n",
        "    if (i+1) % 10 == 0:\n",
        "      model_evaluation(gen_model, dis_model, dataset, x)"
      ],
      "metadata": {
        "id": "ZAI4hzgHUqSk"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUNNING THE MODEL"
      ],
      "metadata": {
        "id": "hOXE2_MDUqte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dis_model=get_discriminator_model()\n",
        "gen_model=get_generator_model()\n",
        "gan_model=get_gan_model(gen_model,dis_model)\n",
        "train(gen_model,dis_model, gan_model, train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1xW1MTrlUpgr",
        "outputId": "7ab661f3-4cb5-4a26-c986-e84842380b25"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 24, 24, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 24, 24, 1), dtype=tf.float32, name=None))>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-f9c4e6b8506e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_generator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_gan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-155-f77a252c2e5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gen_model, dis_model, gan_model, dataset, epochs, batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mbatch_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mhalf_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'PrefetchDataset' object is not subscriptable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "name": "ganfull.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}