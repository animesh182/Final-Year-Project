# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dbalVXViFNmY5uT8JZXCS8vT-6ZjHYeZ

IMPORTS
"""

#MODEL BUILDING IMPORTS
import tensorflow as tf
from tensorflow import keras
from keras import layers, Model
from keras.models import load_model
from keras.applications.vgg19 import VGG19

#DRIVE IMPORT
# from google.colab import drive

#FOR MANAGING AND IMPORTING DATASET
from tensorflow.keras.utils import image_dataset_from_directory
import os
import pathlib

#FOR N-DARRAY 
import numpy as np
from numpy.random import randint

#FOR IMAGE PROCESSING AND PLOTTING
import cv2 as cv
from matplotlib import pyplot as plt

#FOR PROGRESS BAR
from tqdm import tqdm

"""LIST OF GLOBAL VARIABLES"""

train_ds_lr = tf.keras.Input(shape=(48,48,3))
train_ds_hr = tf.keras.Input(shape=(192,192,3))
crop_size = (192, 192)
low_size= (48,48)
batch_size = 8
upscale_factor = 4
low_res_size = 48 
epoch = 300

"""IMPORTING AND MOUNTING DRIVE"""

# drive.mount('/gdrive')
root_dir = "/gdrive/MyDrive/dataset"
root_dir = pathlib.Path(root_dir)

"""MAKING DATASET"""

dataset_dir= os.path.join(root_dir, "finished/train")
train_ds = image_dataset_from_directory(
    dataset_dir,
    labels = None,
    batch_size=batch_size,
    image_size=crop_size,
    shuffle=True,
    seed=1337,  
    label_mode=None,
)

testset = os.path.join(root_dir,"finished")
test_path = os.path.join(testset, "test" )

test_img_paths=sorted(
    [
     os.path.join(test_path,fname)
     for fname in os.listdir(test_path)
     if fname.endswith(".jpg")
    ]
)

"""NORMALIZING PIXEL VALUES BETWEEN 0-1"""

def normalize(images):
  images = tf.cast(images, tf.float32)
  images /= (255)
  return images

# The map function applies the normalize function to each element in the train
# and test datasets
train_ds =  train_ds.map(normalize)
print(train_ds)

"""SEPERATING DATASET INTO LOW-RESOLUTION AND HIGH-RESOLUTION IMAGES"""

def process_input(input, input_size):
    lr_image= tf.image.resize(input, [input_size, input_size], method="bicubic")
    return lr_image



train_ds = train_ds.map(
    lambda x: (process_input(x,input_size=low_res_size),x)
)

"""THE ACTUAL GENERATOR MODEL"""

def residual_block(input):
  residual_model= layers.Conv2D(64, (3,3), padding="same")(input)
  residual_model= layers.BatchNormalization(momentum=0.5)(residual_model)
  residual_model= layers.PReLU(shared_axes=[1,2])(residual_model)
  residual_model= layers.Conv2D(64, (3,3), padding="same")(residual_model)
  residual_model= layers.BatchNormalization(momentum=0.5)(residual_model)
  return layers.add([input, residual_model])

def upscale_block(input):
  up_model= layers.Conv2D(256, (3,3), padding="same")(input)
  up_model= layers.UpSampling2D(size=2)(up_model)
  up_model= layers.PReLU(shared_axes=[1,2])(up_model)
  return up_model

def generator_model(size_of_residual_block=16):
  input = train_ds_lr
  generator_layer= layers.Conv2D(64, (9,9), padding="same")(input)
  generator_layer= layers.PReLU(shared_axes=[1,2])(generator_layer)

  temp_layer= generator_layer

  for i in range(size_of_residual_block):
    generator_layer= residual_block(generator_layer)

  generator_layer= layers.Conv2D(64, (3,3), padding="same")(generator_layer)
  generator_layer= layers.BatchNormalization(momentum=0.5)(generator_layer)
  generator_layer= layers.add([temp_layer, generator_layer])

  generator_layer= upscale_block(generator_layer)
  generator_layer= upscale_block(generator_layer)

  result= layers.Conv2D(3, (9,9), padding="same")(generator_layer)

  return keras.Model(input, result)

"""ACTUAL DISCRIMINATOR MODEL"""

def discriminator_block(input, filter_map_size, strides=1, batch_norm= True):
  discriminator= layers.Conv2D(filter_map_size, (3,3), strides=strides, padding="same")(input)

  if batch_norm:
    discriminator= layers.BatchNormalization(momentum=0.8)(discriminator)

  discriminator= layers.LeakyReLU(alpha=0.2)(discriminator)

  return discriminator

def discriminator_model():
  input = train_ds_hr
  layer01= discriminator_block(input, 64, batch_norm=False)
  layer02= discriminator_block(layer01, 64, strides=2)
  layer03= discriminator_block(layer02, 128)
  layer04= discriminator_block(layer03, 128, strides=2)
  layer05= discriminator_block(layer04, 256)
  layer06= discriminator_block(layer05, 256, strides=2)
  layer07= discriminator_block(layer06, 512)
  layer08= discriminator_block(layer07, 512, strides=2)

  layer_flatten= layers.Flatten()(layer08)
  dense_layer= layers.Dense(1024)(layer_flatten)
  layer_leaky= layers.LeakyReLU(alpha=0.2)(dense_layer)
  validity= layers.Dense(1, activation="sigmoid")(layer_leaky)
  return Model(input, validity)

"""THE VGG MODEL USED AS A REFERENCE"""

def VGG_model(hr_shape):
  vgg= VGG19(weights="imagenet", include_top=False, input_shape=hr_shape)
  return Model(vgg.inputs, vgg.layers[10].output)

"""THE GAN MODEL THAT IS A COMBINATION OF THE GENERATOR, DISCRIMINATOR AND THE VGG MODEL"""

def createGAN(gen_model, disc_model, vgg, lr_ip, hr_ip):
  gen_img= gen_model(lr_ip)
  gen_feature= vgg(gen_img)

  disc_model.trainable= False
  validity= disc_model(gen_img)

  return Model([lr_ip, hr_ip], [validity, gen_feature])

"""CREATING INSTANCES OF THE MODELS"""

lr_ip= train_ds_lr
hr_ip= train_ds_hr

gen_model= generator_model(size_of_residual_block=16)

discriminator= discriminator_model()
discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

vgg= VGG_model((192,192,3))
vgg.trainable=False

SRGAN_model= createGAN(gen_model, discriminator, vgg, lr_ip, hr_ip)
SRGAN_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer="adam")

# Commented out IPython magic to ensure Python compatibility.

def train():
  for e in range(epoch):
    fake_data= np.zeros((batch_size,1))
    real_data= np.ones((batch_size,1))

    g_losses=[]
    d_losses=[]

    for id,data in tqdm(enumerate(train_ds)):
      if(id==495):
        break

      fake_images= gen_model.predict_on_batch(data[0])

      discriminator.trainable= True
      d_loss_gen= discriminator.train_on_batch(fake_images, fake_data)
      d_loss_real= discriminator.train_on_batch(data[1], real_data)
      discriminator.trainable= False

      d_loss= 0.5 * np.add(d_loss_gen, d_loss_real)

      img_features= vgg.predict(data[1])

      g_loss, g01, g02= SRGAN_model.train_on_batch([data[0], data[1]],[real_data, img_features])

      d_losses.append(d_loss)
      g_losses.append(g_loss)

    g_losses= np.array(g_losses)
    d_losses= np.array(d_losses)

    g_loss= np.sum(g_losses, axis=0)/len(g_losses)
    d_loss= np.sum(d_losses, axis=0)/len(d_losses)

    print(f"Epoch:: {e+1}, g_loss:{g_loss}, d_loss:{d_loss}")

    if (e+1)%10==0:
#     %cd /gdrive/MyDrive/dataset/saved_model
      gen_model.save(f"generator_model{str(e+1)}thEpoch.h5")
train()


"""TESTING THE MODEL AGAINST THE TEST SET"""

# enhancer= load_model('gen_e_10.h5', compile=False)
"""
for img in test_img_paths:
  if img.lower().endswith((".jpg",".png", ".jpeg")):
    print(img)
    im= cv.imread(img)
    dim = low_size
      
    im = cv.resize(im, dim, interpolation = cv.INTER_AREA)
    im= cv.cvtColor(im, cv.COLOR_BGR2RGB)
    im=im/255
    im=np.expand_dims(im, axis=0)
"""
"""
    print(im.shape)
    gen_im= enhancer.predict(im)
    
    plt.figure(figsize=(12,6))
    plt.subplot(231)
    plt.title(img)
    plt.imshow(im[0,:,:,:])
    plt.subplot(232)
    plt.title("Generated IMAGE")
    plt.imshow(gen_im[0,:,:,:])
    plt.show()
"""